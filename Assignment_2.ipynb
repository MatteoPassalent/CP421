{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqFkvVih34Zo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "from itertools import combinations\n",
        "from mlxtend.frequent_patterns import association_rules\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import zipfile\n",
        "import requests\n",
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "!unzip /content/drive/MyDrive/CP421/online_retail.zip -d Data"
      ],
      "metadata": {
        "id": "2mNko7rn6n0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/Data/Online Retail.xlsx\"\n",
        "df = pd.read_excel(file_path)"
      ],
      "metadata": {
        "id": "CnHdb4y-9qVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna(subset=['CustomerID', 'StockCode'])\n",
        "df = df[df['Quantity'] > 0]\n",
        "non_product_codes = ['BANK CHARGES', 'C2', 'DOT', 'M', 'PADS', 'POST']\n",
        "df = df[~df['StockCode'].isin(non_product_codes)]"
      ],
      "metadata": {
        "id": "VRu87g_r-cx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Uc7V5yW-42V",
        "outputId": "5f054a8a-02cb-4d5a-ddbb-691b5af7ff25"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  InvoiceNo StockCode                          Description  Quantity  \\\n",
            "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
            "1    536365     71053                  WHITE METAL LANTERN         6   \n",
            "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
            "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
            "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
            "\n",
            "          InvoiceDate  UnitPrice  CustomerID         Country  \n",
            "0 2010-12-01 08:26:00       2.55     17850.0  United Kingdom  \n",
            "1 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
            "2 2010-12-01 08:26:00       2.75     17850.0  United Kingdom  \n",
            "3 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
            "4 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6xEWF4PxAZVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensures StockCode is treated as a string\n",
        "df['StockCode'] = df['StockCode'].astype(str)\n",
        "\n",
        "transactional_data = df.groupby('InvoiceNo')['StockCode'].apply(set).reset_index()\n",
        "transactions = transactional_data['StockCode'].apply(list).tolist()\n",
        "\n",
        "te = TransactionEncoder()\n",
        "binary_matrix = te.fit(transactions).transform(transactions)\n",
        "\n",
        "# Convert to DataFrame\n",
        "binary_df = pd.DataFrame(binary_matrix, columns=te.columns_, index=transactional_data['InvoiceNo'])\n",
        "print(binary_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTS_F-0q-9He",
        "outputId": "b3752944-4bd3-4479-da3e-2e072017d16d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           10002  10080  10120  10123C  10124A  10124G  10125  10133  10135  \\\n",
            "InvoiceNo                                                                     \n",
            "536365     False  False  False   False   False   False  False  False  False   \n",
            "536366     False  False  False   False   False   False  False  False  False   \n",
            "536367     False  False  False   False   False   False  False  False  False   \n",
            "536368     False  False  False   False   False   False  False  False  False   \n",
            "536369     False  False  False   False   False   False  False  False  False   \n",
            "\n",
            "           11001  ...  90214O  90214P  90214R  90214S  90214T  90214U  90214V  \\\n",
            "InvoiceNo         ...                                                           \n",
            "536365     False  ...   False   False   False   False   False   False   False   \n",
            "536366     False  ...   False   False   False   False   False   False   False   \n",
            "536367     False  ...   False   False   False   False   False   False   False   \n",
            "536368     False  ...   False   False   False   False   False   False   False   \n",
            "536369     False  ...   False   False   False   False   False   False   False   \n",
            "\n",
            "           90214W  90214Y  90214Z  \n",
            "InvoiceNo                          \n",
            "536365      False   False   False  \n",
            "536366      False   False   False  \n",
            "536367      False   False   False  \n",
            "536368      False   False   False  \n",
            "536369      False   False   False  \n",
            "\n",
            "[5 rows x 3659 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min_sup = 0.02\n",
        "num_transactions = len(binary_df)\n",
        "\n",
        "# Function to calculate support\n",
        "def get_support(itemset, transactions):\n",
        "    count = sum(transactions[list(itemset)].all(axis=1))\n",
        "    return count / num_transactions\n",
        "\n",
        "# this generates frequent 1-itemsets\n",
        "frequent_itemsets = {}\n",
        "single_items = binary_df.columns\n",
        "L1 = {frozenset([item]): get_support([item], binary_df) for item in single_items}\n",
        "L1 = {k: v for k, v in L1.items() if v >= min_sup}\n",
        "frequent_itemsets[1] = L1\n",
        "\n",
        "# this generates all higher-order frequent itemsets\n",
        "k = 2\n",
        "while len(frequent_itemsets[k - 1]) > 0:\n",
        "    prev_Lk = list(frequent_itemsets[k - 1].keys())\n",
        "    candidate_itemsets = {frozenset(x) for x in combinations(set().union(*prev_Lk), k)}\n",
        "\n",
        "    Lk = {itemset: get_support(itemset, binary_df) for itemset in candidate_itemsets if get_support(itemset, binary_df) >= min_sup}\n",
        "    if len(Lk) == 0:\n",
        "        break\n",
        "    frequent_itemsets[k] = Lk\n",
        "    k += 1\n",
        "\n",
        "k_itemset_counts = {k: len(v) for k, v in frequent_itemsets.items()}\n",
        "\n",
        "result_df = pd.DataFrame(list(k_itemset_counts.items()), columns=['k', 'Number of k-itemsets'])\n",
        "\n",
        "print(result_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPRkLXQtAkBu",
        "outputId": "977e6388-28b8-44b2-fdba-b5fd85955d99"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   k  Number of k-itemsets\n",
            "0  1                   208\n",
            "1  2                    41\n",
            "2  3                     1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# converts  frequent itemsets into format for  mlxtend\n",
        "frequent_itemsets_df = pd.DataFrame([\n",
        "    {'itemsets': itemset, 'support': support} for k, itemsets in frequent_itemsets.items() for itemset, support in itemsets.items()\n",
        "])\n",
        "\n",
        "# creates association rules\n",
        "rules = association_rules(frequent_itemsets_df, metric=\"confidence\", min_threshold=0.5)\n",
        "\n",
        "rules_sorted = rules.sort_values(by=\"confidence\", ascending=False)\n",
        "\n",
        "total_rules = len(rules_sorted)\n",
        "print(f\"Total Association Rules: {total_rules}\")\n",
        "\n",
        "print(rules_sorted[['antecedents', 'consequents', 'support', 'confidence', 'lift']].head(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyzshLBVEI8x",
        "outputId": "986f95a3-d59b-4c25-c99d-a01fec6aa02a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Association Rules: 32\n",
            "       antecedents consequents   support  confidence       lift\n",
            "28  (22698, 22699)     (22697)  0.021190    0.894495  23.825164\n",
            "27  (22698, 22697)     (22699)  0.021190    0.847826  19.928786\n",
            "9          (22698)     (22697)  0.024993    0.827338  22.036408\n",
            "22         (22698)     (22699)  0.023689    0.784173  18.432564\n",
            "0          (22697)     (22699)  0.029394    0.782923  18.403197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"http://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n",
        "zip_path = \"ml-100k.zip\"\n",
        "extract_path = \"ml-100k\"\n",
        "\n",
        "# Download dataset\n",
        "if not os.path.exists(zip_path):\n",
        "    response = requests.get(url)\n",
        "    with open(zip_path, \"wb\") as file:\n",
        "        file.write(response.content)\n",
        "\n",
        "# Extract dataset\n",
        "if not os.path.exists(extract_path):\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall()\n",
        "\n",
        "# Load ratings data\n",
        "ratings_path = os.path.join(extract_path, \"u.data\")\n",
        "column_names = [\"user_id\", \"movie_id\", \"rating\", \"timestamp\"]\n",
        "ratings_df = pd.read_csv(ratings_path, sep=\"\\t\", names=column_names)"
      ],
      "metadata": {
        "id": "vaPlWkt4NwOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filters users with at least 20 ratings\n",
        "user_counts = ratings_df[\"user_id\"].value_counts()\n",
        "active_users = user_counts[user_counts >= 20].index\n",
        "filtered_ratings = ratings_df[ratings_df[\"user_id\"].isin(active_users)]\n",
        "\n",
        "# Filters movies rated by at least 20 users\n",
        "movie_counts = filtered_ratings[\"movie_id\"].value_counts()\n",
        "popular_movies = movie_counts[movie_counts >= 20].index\n",
        "filtered_ratings = filtered_ratings[filtered_ratings[\"movie_id\"].isin(popular_movies)]"
      ],
      "metadata": {
        "id": "wZ_6To0yP2-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_ratings = filtered_ratings.sort_values(by=\"timestamp\")\n",
        "\n",
        "# Performs sequential 80-20 split\n",
        "train_df, test_df = train_test_split(filtered_ratings, test_size=0.2, shuffle=False)\n",
        "\n",
        "# Ensure all users and movies in the test set exist in the training set\n",
        "train_users = set(train_df[\"user_id\"])\n",
        "train_movies = set(train_df[\"movie_id\"])\n",
        "\n",
        "test_df = test_df[test_df[\"user_id\"].isin(train_users) & test_df[\"movie_id\"].isin(train_movies)]"
      ],
      "metadata": {
        "id": "Mq5vCcQgQXsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create user-item matrix\n",
        "train_matrix = train_df.pivot(index=\"user_id\", columns=\"movie_id\", values=\"rating\").fillna(0).to_numpy()\n",
        "\n",
        "# SVD decomposition\n",
        "U, S, Vt = np.linalg.svd(train_matrix, full_matrices=False)\n",
        "\n",
        "# Converts to a diagonal matrix\n",
        "S = np.diag(S)"
      ],
      "metadata": {
        "id": "Vwm0dObuSXVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reconstruct_matrix(k):\n",
        "    S_k = S[:k, :k]  # only the top-k singular values\n",
        "    U_k = U[:, :k]    # first k columns of U\n",
        "    Vt_k = Vt[:k, :]  # first k rows of Vt\n",
        "\n",
        "    return np.dot(np.dot(U_k, S_k), Vt_k)\n",
        "\n",
        "def evaluate_predictions(true_df, predicted_matrix):\n",
        "    true_values = []\n",
        "    predicted_values = []\n",
        "\n",
        "    for _, row in true_df.iterrows():\n",
        "        user_id, movie_id, true_rating = row[\"user_id\"], row[\"movie_id\"], row[\"rating\"]\n",
        "\n",
        "        # Get predicted rating\n",
        "        if user_id in predicted_matrix.index and movie_id in predicted_matrix.columns:\n",
        "            predicted_rating = predicted_matrix.loc[user_id, movie_id]\n",
        "            true_values.append(true_rating)\n",
        "            predicted_values.append(predicted_rating)\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(true_values, predicted_values))\n",
        "    mae = mean_absolute_error(true_values, predicted_values)\n",
        "\n",
        "    return rmse, mae\n"
      ],
      "metadata": {
        "id": "73ccnSAIX_Os"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_values = [5, 10, 20, 40]\n",
        "results = {}\n",
        "\n",
        "for k in k_values:\n",
        "    # Reconstruct matrix\n",
        "    reconstructed_matrix = reconstruct_matrix(k)\n",
        "\n",
        "    # Convert reconstructed matrix to DataFrame\n",
        "    predicted_ratings = pd.DataFrame(reconstructed_matrix,\n",
        "                                     index=train_df[\"user_id\"].unique(),\n",
        "                                     columns=train_df[\"movie_id\"].unique())\n",
        "\n",
        "    rmse, mae = evaluate_predictions(test_df, predicted_ratings)\n",
        "    results[k] = {\"RMSE\": rmse, \"MAE\": mae}\n",
        "\n",
        "# Converts to a DataFrame\n",
        "results_df = pd.DataFrame(results).T\n",
        "\n",
        "# Display results\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1Np-TM1YX_n",
        "outputId": "5e5991c6-7948-44c7-d9d4-98b51d580c12"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        RMSE       MAE\n",
            "5   3.349949  3.067795\n",
            "10  3.355537  3.063695\n",
            "20  3.375836  3.076674\n",
            "40  3.396249  3.089789\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lower values of k such as k=5 perform best, as increasing k leads to slight\n",
        "overfitting with diminishing improvements. Matrix factorization captures latent user-item\n",
        "relationships and handles sparse data better, making it good for recommendations.\n",
        "However, it struggles with the cold start problem, scalability, and it also assumes linear\n",
        "interactions, limiting its ability to capture complex preferences."
      ],
      "metadata": {
        "id": "dDoZnRsNsdrV"
      }
    }
  ]
}